---
title: "House Prices"
subtitle: "Advanced Regression Techniques"
author: "Arno Zeng"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
  github_document:
    toc: true
  pdf_document:
    toc: true
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load packages}
library(readr) # read_csv
library(dplyr) # filter, mutate, select, ...
library(tidyr) # gather
```

## Preprocessing

### Import data

```{r read data}
train <- read_csv("../data/raw/train.csv", col_names = TRUE)
test  <- read_csv("../data/raw/test.csv" , col_names = TRUE)
```

```{r}
head(train)
```

```{r}
head(test)
```

It is observed that the train and test datasets differ by one column, `SalePrice`, which is the target variable we aim to predict.

Based on our initial inspection of the imported train and test datasets, we observe that many columns are categorized as strings. At this point, it is necessary to compare the descriptions of these data to determine whether converting the string variables into factors is appropriate.

By comparing the descriptions provided on [kaggle](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data), also in `../data/raw/data_description.txt` for each column, we identified that all columns with string values should indeed be treated as factors. Additionally, we discovered that certain columns marked as double, such as `MSSubClass`, `OverallQual`, and `OverallCond`, should actually be considered as factors based on the nature of their data.

Additionally, the Id column is not required for our analysis, so we will remove it from both the train and test datasets.

```{r correcting data type}
train <- train |>
    mutate(across(c(MSSubClass, OverallQual, OverallCond), as.factor)) |> 
    mutate(across(where(is.character), as.factor)) |> 
    select(-Id) # remove Id

test <- test |>
    mutate(across(c(MSSubClass, OverallQual, OverallCond), as.factor)) |> 
    mutate(across(where(is.character), as.factor)) |> 
    select(-Id) # remove Id
```

Let's take another look at our data to ensure that we have made the necessary adjustments and understand its structure before proceeding further.

```{r}
head(train)
```

```{r}
head(test)
```

At this point, the data import process is complete, and we are ready to proceed with the next steps.

### Fill NA

```{r NA info}
# na info for train data set
train_na_info <- train |> 
  select(where(~ any(is.na(.)))) |> # select cols with na
  summarise_all(~ class(.)) |>      # mark corresponding data type
  pivot_longer(                     # formatting
    cols = everything(), 
    names_to = "ColumnName", 
    values_to = "DataType"
  ) |> 
  mutate(Source = "train")          # mark source

# na info for test data set
test_na_info <- test |> 
  select(where(~ any(is.na(.)))) |> # select cols with na
  summarise_all(~ class(.)) |>      # mark corresponding data type
  pivot_longer(                     # formatting
    cols = everything(), 
    names_to = "ColumnName", 
    values_to = "DataType"
  ) |> 
  mutate(Source = "test")           # mark source

# combined na info for train and test
combined_na_info <- full_join(
    train_na_info, test_na_info, 
    by = c("ColumnName", "DataType")
  ) |>
  mutate(Source = case_when(
    !is.na(Source.x) & !is.na(Source.y) ~ "both",  # if this col has na in both
    !is.na(Source.x) ~ "train",                    # train and test, we mark 
    !is.na(Source.y) ~ "test"                      # the source as "both"
  )) |>
  select(ColumnName, DataType, Source) |>  # drop col Source.x and Source.y
  distinct()                               # make sure no duplicated rows

# output
combined_na_info
```

The above code provides us with a dataframe that contains all columns with missing values (NA). If a column contains NA values in both the train and test datasets, we label its `Source` as "both."

For different variables, we will apply various methods to impute the missing values based on their attributes and data formats. This approach ensures that the imputation method is appropriate for the type and nature of the data in each column.

### Outlier Detection and Handling